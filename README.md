# Swift OpenAI Realtime API Client

A Swift Package Manager library for real-time voice conversations with OpenAI's GPT models. Talk to ChatGPT naturally using your voice - like Siri, but powered by OpenAI's advanced language models.

## ğŸ¯ Features

- âœ… **Real-time Voice Chat** - Direct audio conversations with OpenAI's GPT models
- âœ… **WebRTC Integration** - High-quality audio capture and playback
- âœ… **Secure API Management** - Bitwarden integration for safe API key storage
- âœ… **Swift Package Manager** - Easy integration into iOS/macOS projects
- ğŸš§ **Audio Streaming Pipeline** - Bidirectional audio streaming (in development)
- ğŸš§ **Session Configuration** - Customizable AI personality and voice settings

## ğŸš€ Quick Start

### Requirements

- macOS 12.0+
- Swift 5.7+
- OpenAI API key with Realtime API access
- Bitwarden CLI (for secure API key management)

### Installation

Add this package to your Swift project:

```swift
dependencies: [
    .package(url: "https://github.com/MaxMeyberg/Swift_Project.git", from: "1.0.0")
]
```

### Basic Usage

```swift
import SwiftOpenAIRealtime

// Initialize the client
let client = OpenAIRealtimeClient(apiKey: "your-openai-api-key")

// Connect to OpenAI
client.connect()

// Connection status will be logged automatically
// Look for: "âœ… Connected to OpenAI Realtime API!"
```

### Secure API Key Setup

We recommend using Bitwarden for secure API key management:

```bash
# Install Bitwarden CLI
brew install bitwarden-cli

# Store your OpenAI API key
bw create item '{"type":1,"name":"Open AI API Key","login":{"password":"your-sk-key-here"}}'

# Use in your app
export OPENAI_API_KEY="$(bw get password 'Open AI API Key')"
```

## ğŸ—ï¸ Architecture

```
Your Voice â†’ WebRTC â†’ OpenAI Realtime API â†’ AI Response â†’ Your Speakers
```

### Core Components

- **WebRTC Module**: Handles audio capture from microphone and playbook to speakers
- **OpenAI Client**: Manages WebSocket connection to OpenAI's Realtime API
- **Security Layer**: Secure API key management with Bitwarden integration

## ğŸ“‹ Current Status

### âœ… Working Features
- [x] WebRTC audio framework integration
- [x] OpenAI Realtime API connection
- [x] WebSocket session management
- [x] Secure API key handling
- [x] Connection status monitoring
- [x] Comprehensive test suite

### ğŸš§ In Development
- [ ] Audio format conversion (WebRTC â†” PCM16)
- [ ] Bidirectional audio streaming
- [ ] Session configuration options
- [ ] Voice chat interface

## ğŸ§ª Testing

The package includes comprehensive tests for both WebRTC and OpenAI integration:

```bash
# Run all tests
swift test

# Test WebRTC integration
swift test --filter WebRTCTests

# Test OpenAI connection (requires API key)
export OPENAI_API_KEY="your-key-here"
swift test --filter OpenAIRealtimeTests
```

### Test Results
```
âœ… WebRTC Factory Creation: PASSED
âœ… WebRTC Peer Connection: PASSED  
âœ… OpenAI API Key Format: PASSED
âœ… OpenAI WebSocket Connection: PASSED
âœ… OpenAI Session Creation: PASSED
```

## ğŸ”§ Technical Specifications

### Audio Format
- **Sample Rate**: 24,000 Hz
- **Bit Depth**: 16-bit PCM
- **Channels**: Mono
- **Format**: Linear PCM, little-endian

### OpenAI Configuration
- **Model**: `gpt-4o-realtime-preview-2024-10-01`
- **Voice**: `alloy` (configurable)
- **Modalities**: Audio + Text
- **Protocol**: WebSocket over WSS

## ğŸ”’ Security

### API Key Protection
- âœ… Bitwarden integration for secure storage
- âœ… `.gitignore` prevents accidental commits
- âœ… GitHub push protection enabled
- âœ… Environment variable isolation

### Network Security
- âœ… WSS (encrypted WebSocket) connections
- âœ… Bearer token authentication
- âœ… Secure header handling

## ğŸ“– Documentation

### Connection Example
```swift
let client = OpenAIRealtimeClient(apiKey: apiKey)

// Connect with status monitoring
client.connect()

// Check connection status
client.checkConnectionStatus()
// Output:
// ğŸ“Š WebSocket State: running
// ğŸ“Š Is Connected: true

// Disconnect when done
client.disconnect()
```

### Session Information
When connected, OpenAI provides session details:
```json
{
  "type": "session.created",
  "session": {
    "id": "sess_...",
    "voice": "alloy",
    "input_audio_format": "pcm16",
    "output_audio_format": "pcm16",
    "modalities": ["audio", "text"]
  }
}
```

## ğŸš§ Development Roadmap

### Phase 1: Foundation âœ…
- [x] Swift Package setup
- [x] WebRTC integration
- [x] OpenAI API connection
- [x] Security implementation

### Phase 2: Audio Pipeline ğŸš§
- [ ] Audio format conversion
- [ ] Real-time audio streaming
- [ ] Audio buffering and synchronization

### Phase 3: User Experience
- [ ] Voice chat interface
- [ ] Session configuration
- [ ] Error handling and recovery
- [ ] Conversation history

### Phase 4: Advanced Features
- [ ] iOS compatibility
- [ ] Multiple voice options
- [ ] Custom instructions
- [ ] Multi-modal support

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Development Setup
```bash
# Clone the repository
git clone https://github.com/MaxMeyberg/Swift_Project.git
cd Swift_Project

# Install dependencies
swift package resolve

# Run tests
swift test
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **OpenAI** for the Realtime API
- **Google** for the WebRTC framework
- **Swift Community** for excellent package management tools

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/MaxMeyberg/Swift_Project/issues)
- **Discussions**: [GitHub Discussions](https://github.com/MaxMeyberg/Swift_Project/discussions)
- **Documentation**: [Wiki](https://github.com/MaxMeyberg/Swift_Project/wiki)

---

**Status**: Foundation Complete âœ… | **Next**: Audio Pipeline Integration ğŸš§

Made with â¤ï¸ for the Swift and AI community