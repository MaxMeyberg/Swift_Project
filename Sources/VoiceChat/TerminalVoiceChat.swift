import Foundation
import SwiftOpenAIRealtime
import WebRTC

@available(macOS 12.0, *)
class TerminalVoiceChat {
    private let client: OpenAIRealtimeClient
    private var isRunning = false
    private var isRecording = false
    
    init(apiKey: String) {
        self.client = OpenAIRealtimeClient(apiKey: apiKey)
    }
    
    func start() async {
        print("ğŸ”Œ Connecting to OpenAI...")
        
        // Connect to OpenAI
        client.connect()
        
        // Wait for connection
        try? await Task.sleep(nanoseconds: 3_000_000_000) // 3 seconds
        
        if client.isConnected {
            print("âœ… Connected to OpenAI Realtime API!")
            await runChatLoop()
        } else {
            print("âŒ Failed to connect to OpenAI")
            return
        }
    }
    
    private func runChatLoop() async {
        print("\nğŸ¤ Voice Chat Ready!")
        print("ğŸ“¢ Instructions:")
        print("   - Press 's' + ENTER for status")
        print("   - Press 't' + ENTER to test audio")
        print("   - Press 'q' + ENTER to quit")
        print("\nğŸŸ¢ Ready for commands...")
        
        isRunning = true
        
        // Setup keyboard input handling
        setupKeyboardInput()
        
        // Keep the chat running
        while isRunning {
            try? await Task.sleep(nanoseconds: 100_000_000) // 0.1 seconds
        }
        
        client.disconnect()
        print("\nğŸ‘‹ Voice chat ended. Goodbye!")
    }
    
    private func setupKeyboardInput() {
        Task {
            while isRunning {
                if let input = readLine() {
                    switch input.lowercased() {
                    case "q", "quit", "exit":
                        print("ğŸ›‘ Shutting down...")
                        isRunning = false
                    case "s", "status":
                        showStatus()
                    case "t", "test":
                        testAudio()
                    case "h", "help":
                        showHelp()
                    default:
                        print("â“ Unknown command '\(input)'. Type 'h' for help")
                    }
                }
            }
        }
    }
    
    private func showStatus() {
        print("\nğŸ“Š Voice Chat Status:")
        print("ğŸ”Œ OpenAI Connected: \(client.isConnected ? "âœ…" : "âŒ")")
        print("ğŸ¤ Recording: \(isRecording ? "ğŸ”´" : "âš«")")
        print("ğŸ™ï¸ Chat Running: \(isRunning ? "âœ…" : "âŒ")")
        client.checkConnectionStatus()
        print("ğŸŸ¢ Ready for commands...\n")
    }
    
    private func testAudio() {
        print("\nğŸ”§ Testing audio setup...")
        
        let factory = RTCPeerConnectionFactory()
        let audioSource = factory.audioSource(with: nil)
        let audioTrack = factory.audioTrack(with: audioSource, trackId: "test")
        
        if audioTrack.isEnabled {
            print("âœ… Audio system working")
            print("ğŸ¤ Microphone: Ready")
            print("ğŸ”Š Speakers: Ready")
            print("ğŸ“Š Audio track ID: \(audioTrack.trackId)")
        } else {
            print("âŒ Audio system not working")
        }
        print("ğŸŸ¢ Ready for commands...\n")
    }
    
    private func showHelp() {
        print("\nğŸ“– Available Commands:")
        print("   s - Show connection status")
        print("   t - Test audio system")
        print("   h - Show this help")
        print("   q - Quit voice chat")
        print("ğŸŸ¢ Ready for commands...\n")
    }
    
    // TODO: Implement actual audio recording/playback in Phase 2
    private func startRecording() {
        print("ğŸ”´ Recording... speak now!")
        isRecording = true
        // Audio capture will be implemented here
    }
    
    private func stopRecording() {
        print("ğŸ“¤ Sending to OpenAI...")
        isRecording = false
        // Audio processing and sending will be implemented here
    }
}